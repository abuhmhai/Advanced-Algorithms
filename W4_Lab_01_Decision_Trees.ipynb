{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ungraded Lab: Decision Trees",
   "id": "88e700fd6c0470b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this notebook you will visualize how a decision tree is splitted using information gain.\n",
    "\n",
    "We will revisit the dataset used in the video lectures. The dataset is:"
   ],
   "id": "bed117976c30f3f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As you saw in the lectures, in a decision tree, we decide if a node will be split or not by looking at the **information gain** that split would give us. (Image of video IG)\n",
    "\n",
    "Where\n",
    "\n",
    "$$\\text{Information Gain} = H(p_1^\\text{node})- \\left(w^{\\text{left}}H\\left(p_1^\\text{left}\\right) + w^{\\text{right}}H\\left(p_1^\\text{right}\\right)\\right),$$\n",
    "\n",
    "and $H$ is the entropy, defined as\n",
    "\n",
    "$$H(p_1) = -p_1 \\text{log}_2(p_1) - (1- p_1) \\text{log}_2(1- p_1)$$\n",
    "\n",
    "Remember that log here is defined to be in base 2. Run the code block below to see by yourself how the entropy. $H(p)$ behaves while $p$ varies.\n",
    "\n",
    "Note that the H attains its higher value when $p = 0.5$. This means that the probability of event is $0.5$. And its minimum value is attained in $p = 0$ and $p = 1$, i.e., the probability of the event happening is totally predictable. Thus, the entropy shows the degree of predictability of an event."
   ],
   "id": "2b870fa3700f4d35"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T17:44:25.535906Z",
     "start_time": "2024-07-16T17:44:20.642122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *"
   ],
   "id": "e2632049d0e5c071",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T17:44:33.161896Z",
     "start_time": "2024-07-16T17:44:32.597908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%matplotlib widget\n",
    "_ = plot_entropy()\n"
   ],
   "id": "bff4d1fa35872e25",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_entropy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmatplotlib\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwidget\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m _ \u001B[38;5;241m=\u001B[39m \u001B[43mplot_entropy\u001B[49m()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'plot_entropy' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "|                                                     |   Ear Shape | Face Shape | Whiskers |   Cat  |\n",
    "|:---------------------------------------------------:|:---------:|:-----------:|:---------:|:------:|\n",
    "| <img src=\"images/0.png\" alt=\"drawing\" width=\"50\"/> |   Pointy   |   Round     |  Present  |    1   |\n",
    "| <img src=\"images/1.png\" alt=\"drawing\" width=\"50\"/> |   Floppy   |  Not Round  |  Present  |    1   |\n",
    "| <img src=\"images/2.png\" alt=\"drawing\" width=\"50\"/> |   Floppy   |  Round      |  Absent   |    0   |\n",
    "| <img src=\"images/3.png\" alt=\"drawing\" width=\"50\"/> |   Pointy   |  Not Round  |  Present  |    0   |\n",
    "| <img src=\"images/4.png\" alt=\"drawing\" width=\"50\"/> |   Pointy   |   Round     |  Present  |    1   |\n",
    "| <img src=\"images/5.png\" alt=\"drawing\" width=\"50\"/> |   Pointy   |   Round     |  Absent   |    1   |\n",
    "| <img src=\"images/6.png\" alt=\"drawing\" width=\"50\"/> |   Floppy   |  Not Round  |  Absent   |    0   |\n",
    "| <img src=\"images/7.png\" alt=\"drawing\" width=\"50\"/> |   Pointy   |  Round      |  Absent   |    1   |\n",
    "| <img src=\"images/8.png\" alt=\"drawing\" width=\"50\"/> |    Floppy  |   Round     |  Absent   |    0   |\n",
    "| <img src=\"images/9.png\" alt=\"drawing\" width=\"50\"/> |   Floppy   |  Round      |  Absent   |    0   |\n",
    "\n",
    "\n",
    "We will use **one-hot encoding** to encode the categorical features. They will be as follows:\n",
    "\n",
    "- Ear Shape: Pointy = 1, Floppy = 0\n",
    "- Face Shape: Round = 1, Not Round = 0\n",
    "- Whiskers: Present = 1, Absent = 0\n",
    "\n",
    "Therefore, we have two sets:\n",
    "\n",
    "- `X_train`: for each example, contains 3 features:\n",
    "    - Ear Shape (1 if pointy, 0 otherwise)\n",
    "    - Face Shape (1 if round, 0 otherwise)\n",
    "    - Whiskers (1 if present, 0 otherwise)\n",
    "\n",
    "    - `y_train`: whether the animal is a cat\n",
    "    - 1 if the animal is a cat\n",
    "    - 0 otherwise"
   ],
   "id": "4117cbdeb85203ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T17:45:28.882077Z",
     "start_time": "2024-07-16T17:45:28.821412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = np.array([[1, 1, 1],\n",
    "                    [0, 0, 1],\n",
    "                    [0, 1, 0],\n",
    "                    [1, 0, 1],\n",
    "                    [1, 1, 1],\n",
    "                    [1, 1, 0],\n",
    "                    [0, 0, 0],\n",
    "                    [1, 1, 0],\n",
    "                    [0, 1, 0],\n",
    "                    [0, 1, 0]])\n",
    "\n",
    "y_train = np.array([1, 1, 0, 0, 1, 1, 0, 1, 0, 0])"
   ],
   "id": "b597b1b66ae05748",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T17:45:51.202307Z",
     "start_time": "2024-07-16T17:45:51.169179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For instance the first example\n",
    "X_train[0]"
   ],
   "id": "ac1da2ddee9ea0dc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This means that the first example has a pointy ear shape, round face shape and it has whiskers.",
   "id": "5a68d7e4ce11ea3d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "On each node, we compute the information gain for each feature, then split the node on the feature with the higher information gain, by comparing the entropy of the node with the weighted entropy in the two splitted nodes. ",
   "id": "d7d516b7c7223ad1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "So, the root node has every animal in our dataset. Remember that $p_1^{node}$ is the proportion of positive class (cats) in the root node. So\n",
    "\n",
    "$$p_1^{node} = \\frac{5}{10} = 0.5$$\n",
    "\n",
    "Now let's write a function to compute the entropy."
   ],
   "id": "46ea349adedff67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T17:48:17.582016Z",
     "start_time": "2024-07-16T17:48:17.550945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def entropy(p):\n",
    "    if p==0 or p == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return -p * np.log2(p) - (1- p)*np.log2(1 - p)\n",
    "print(entropy(0.5))"
   ],
   "id": "15999674fae854ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To illustrate, let's compute the information gain if we split the node for each of the features. To do this, let's write some functions.",
   "id": "169e982bf72d2005"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T17:49:44.597406Z",
     "start_time": "2024-07-16T17:49:44.579638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_indices(X, index_features):\n",
    "    \"\"\"Given a dataset and a index feature, return two lists for the two split nodes, the left node has the animals that have \n",
    "    that feature = 1 and the right node those that have the feature = 0 \n",
    "    index feature = 0 => ear shape\n",
    "    index feature = 1 => face shape\n",
    "    index feature = 2 => whiskers\n",
    "    \"\"\"\n",
    "    left_indices = []\n",
    "    right_indices = []\n",
    "    for i,x in enumerate(X):\n",
    "        if x[index_features] == 1:\n",
    "            left_indices.append(i)\n",
    "        else:\n",
    "            right_indices.append(i)\n",
    "        return left_indices, right_indices\n",
    "        \n",
    "        "
   ],
   "id": "b20b04a9b492823b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "148edab63573db3a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
