{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Optional Lab: Diagnosing Bias and Variance\n",
    "\n",
    "In the previous optional lab, you saw how to evaluate a learning algorithm's performance by measuring its training and cross validation error. Given these values, you are able to quantify how well a model is doing and this helps you make a decision on which one to use for a given application. In this lab, you will build upon this process and explore some tips to improve the performance of your models. As it turns out, the training and cross validation errors can tell you what to try next to improve your models. Specifically, it will show if you have a high bias (underfitting) or high variance (overfitting) problem. This lecture slide shown below gives an example:\n",
    "\n",
    "<img src='images/C2_W3_BiasVariance.png' width=75%>\n",
    "\n",
    "The leftmost figure shows a high bias problem where the model is not capturing the patterns in the training data. As a result, you will have a high training and cross validation error. The rightmost figure, on the other hand, shows a high variance problem where the model has overfit the training set. Thus, even though it has a low training error, it will perform poorly on new examples. That is indicated by a high cross validation error. The ideal model would be the figure in the middle, where it successfully learns from the training set and also generalizes well to unseen data. The lectures gave some tips on what to do next to achieve this \"just right\" model.\n",
    "\n",
    "To fix a high bias problem, you can:\n",
    "* try adding polynomial features\n",
    "* try getting additional features\n",
    "* try decreasing the regularization parameter\n",
    "\n",
    "To fix a high variance problem, you can:\n",
    "* try increasing the regularization parameter\n",
    "* try smaller sets of features\n",
    "* get more training examples\n",
    "\n",
    "You will try all these tips in this lab. Let's begin!"
   ],
   "id": "b7c33ad84d0e18df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Establishing Baseline Level of Performance\n",
    "\n",
    "Before you can diagnose a model for high bias or high variance, it is usually helpful to first have an idea of what level of error you can reasonably get to. As mentioned in class, you can use any of the following to set a baseline level of performance.\n",
    "\n",
    "* human level performance\n",
    "* competing algorithm's performance\n",
    "* guess based on experience\n",
    "\n",
    "Real-world data can be very noisy and it's often infeasible to get to 0% error. For example, you might think that you have a high bias problem because you're getting 10% training and 15% cross validation error on a computer vision application. However, you later found out that even humans can't perform better than 10% error. If you consider this the baseline level, then you now instead have a high variance problem because you've prioritized minimizing the gap between cross validation and training error.\n",
    "\n",
    "With this in mind, let's begin exploring the techniques to address these issues."
   ],
   "id": "91d1e2435cf4c847"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Imports and Lab Setup\n",
    "\n",
    "Aside from a couple of [linear regressors](https://scikit-learn.org/stable/modules/classes.html#classical-linear-regressors) from scikit-learn, all other functions used in this lab are found in the `utils.py` file outside this notebook. You will mostly use the same code as the last lab so you don't need to see each line here again. It mostly contains functions to split your data, as well as functions that loop over a list of parameters (e.g. degree of polynomial, regularization parameter) and plots the training and cross validation error for each one. Feel free to explore the code in the said file to see the implementation."
   ],
   "id": "58baa4d71566d900"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T20:40:42.586036Z",
     "start_time": "2024-07-09T20:40:42.580645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for building linear regression models\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "import utils\n"
   ],
   "id": "959cfb16a44a126e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c20249cf805c7579"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
